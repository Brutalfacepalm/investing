version: '3.8'

services:

  mongo:
    image: mongo:6.0.6-jammy
    restart: always
    container_name: mongo
    environment:
      MONGO_INITDB_ROOT_USERNAME: operate_database
      MONGO_INITDB_ROOT_PASSWORD: operate_database
    ports:
      - 27017:27017
    volumes:
      - mongo:/data/db
    networks:
      flask:

  mongo-express:
    image: mongo-express
    restart: always
    container_name: mongo-express
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: operate_database
      ME_CONFIG_MONGODB_ADMINPASSWORD: operate_database
      ME_CONFIG_MONGODB_URL: mongodb://operate_database:operate_database@mongo:27017/
    expose:
      - 8081
    depends_on:
      - mongo
    networks:
      flask:

  flask:
    build:
      context: ./services/flask_app
      dockerfile: ./Dockerfile
    container_name: flask
#    platform: linux/amd64
    command: gunicorn --bind 0.0.0.0:8000 app:app
#    command: python3 app.py
    volumes:
      - static:/home/app/flask_app/static
      - logs:/home/app/flask_app/logs
      - ./services/flask_app/templates:/home/app/flask_app/templates
      - ./services/flask_app:/home/app/flask_app
    expose:
      - 8000
    env_file:
      - .env.dev
    depends_on:
      - mongo
    networks:
      flask:

  kafka_data_worker:
    build:
      context: ./services/kafka
      dockerfile: ./Dockerfile
    container_name: kafka_data_worker
    restart: always
    command: python data_worker.py -f data -t features  -bs 192.168.1.13:39092 -db1 investing_main_user:investing_main_user:investing_db:192.168.1.15:5432 -db2 operate_database:operate_database:mongo:27017:investing
    volumes:
      - ./services/service_files:/home/app
      - type: bind
          source: models
          target: /home/app
    depends_on:
      - kafka_feature_worker
    networks:
      flask:

  kafka_feature_worker:
    build:
      context: ./services/kafka
      dockerfile: ./Dockerfile
    container_name: kafka_feature_worker
    restart: always
    command: python data_worker.py -f features -t predicts -bs 192.168.1.13:39092 -db1 investing_main_user:investing_main_user:investing_db:192.168.1.15:5432 -db2 operate_database:operate_database:mongo:27017:investing
    volumes:
      - ./services/service_files:/home/app
      - type: bind
          source: models
          target: /home/app
    depends_on:
      - kafka_predicts_worker
    networks:
      flask:

  kafka_predicts_worker:
    build:
      context: ./services/kafka
      dockerfile: ./Dockerfile
    container_name: kafka_predicts_worker
    restart: always
    command: python data_worker.py -f predicts -t empty -bs 192.168.1.13:39092 -db1 investing_main_user:investing_main_user:investing_db:192.168.1.15:5432 -db2 operate_database:operate_database:mongo:27017:investing
    volumes:
      - ./services/service_files:/home/app
      - type: bind
          source: models
          target: /home/app
    depends_on:
      - broker1
      - zookeeper
    networks:
      flask:

  prometheus:
    image: prom/prometheus
    container_name: prometheus
    restart: unless-stopped
    volumes:
      - ./services/prometheus/config.yml:/etc/prometheus/prometheus.yml
      - prometheus:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    expose:
      - 9090
    depends_on:
      - flask
    networks:
      flask:

  grafana:
    image: grafana/grafana
    container_name: grafana
    volumes:
      - ./services/grafana/config.ini:/etc/grafana/grafana.ini
      - ./services/grafana/datasource.yml:/etc/grafana/provisioning/datasources/default.yml
      - ./services/grafana/dashboard.yml:/etc/grafana/provisioning/dashboards/default.yml
      - ./services/grafana/dashboards:/var/lib/grafana/dashboards
      - grafana_data:/var/lib/grafana
    environment:
        GF_SECURITY_ADMIN_USER: 'grafana_admin'
        GF_SECURITY_ADMIN_PASSWORD: 'grafana_admin'
        GF_USERS_ALLOW_SIGN_UP: 'false'
    expose:
      - 3000
    depends_on:
      - prometheus
    networks:
      flask:

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - 22181:2181
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      flask:
    volumes:
      - ~/kafka/data/zookeeper_data:/var/lib/zookeeper/data
      - ~/kafka/data/zookeeper_log:/var/lib/zookeeper/log

  broker1:
    image: confluentinc/cp-server:latest
    container_name: broker1
    restart: always
    depends_on:
      - zookeeper
    ports:
      - 39092:39092
      - 29092:29092
      - 9101:9101
    environment:
      KAFKA_BROKER_ID: 1
      ALLOW_PLAINTEXT_LISTENER: "yes"
      KAFKA_ZOOKEEPER_CONNECT: 192.168.1.13:22181
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://broker1:9092,EXTERNAL://localhost:29092,EXTERNAL_DIFFERENT://192.168.1.13:39092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,EXTERNAL_DIFFERENT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: EXTERNAL_DIFFERENT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_LOG_RETENTION_HOURS: 24
      KAFKA_LOG_RETENTION_BYTES: 1073741824
      KAFKA_LOG_SEGMENT_BUTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 20000
      KAFKA_LOG_SEGMENT_DELETE_DELAY_MS: 1000
      KAFKA_METADATA_MAX_RETENTION_MS: 86400000
      KAFKA_OFFSETS_RETENTION_MINUTES: 14400000
      KAFKA_LOG_CLEANER_DELETE_RETENTION_MS: 3600000
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_HEAP_OPTS: "-Xms512m -Xmx512m"
      CONFLUENT_METRICS_ENABLE: 'false'
    networks:
      flask:

  control-center:
    image: confluentinc/cp-enterprise-control-center:latest
    hostname: control-center
    container_name: control-center
    restart: always
    depends_on:
      - broker1
      - zookeeper
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: PLAINTEXT://192.168.1.13:39092,PLAINTEXT://192.168.1.15:39093,PLAINTEXT://192.168.1.15:39094
      CONTROL_CENTER_ZOOKEEPER_CONNECT: "192.168.1.13:22181"
      CONTROL_CENTER_REPLICATION_FACTOR: 3
      CONTROL_CENTER_INTERNAL_TOPICS_REPLICATION: 3
      CONTROL_CENTER_COMMAND_TOPIC_REPLICATION: 3
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_REPLICATION: 3
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 3
      CONTROL_CENTER_COMMAND_TOPIC_PARTITIONS: 3
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 3
      PORT: 9021
    networks:
      flask:

  nginx:
    build:
      context: ./services/nginx
      dockerfile: ./Dockerfile
      args:
        NGINX_CONFIG_PATH: site-nginx.conf
    container_name: flask_nginx
    restart: on-failure
    volumes:
      - static:/home/app/flask_app/static
    ports:
      - 80:80
      - 1337:80
      - 4040:4040
      - 8081:8081
      - 9090:9090
    depends_on:
      - flask
      - mongo-express
    networks:
      flask:

networks:
    flask:

volumes:
    static:
    logs:
    mongo:
    prometheus:
    grafana_data:

