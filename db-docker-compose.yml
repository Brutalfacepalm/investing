version: '3.8'
x-airflow-common:
  &airflow-common
  build:
    context: ./services/airflow
    dockerfile: ./Dockerfile
  environment:
    - AIRFLOW__CORE__EXECUTOR=LocalExecutor
    - AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS=False
    - AIRFLOW__CORE__LOAD_EXAMPLES=False
    - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://investing_main_user:investing_main_user@postgres:5432/airflow
    - AIRFLOW__CORE__STORE_DAG_CODE=True
    - AIRFLOW__CORE__STORE_SERIALIZED_DAGS=True
    - AIRFLOW__CORE__FERNET_KEY=hjIFXCPQL6ZZx-dN7Kpr5yULTMFmLK-skgH9KdKeA1I=
    - AIRFLOW__CORE__LOGGING_LEVEL=INFO
    - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
    - AIRFLOW__CORE__DEFAULT_TIMEZONE=Europe/Moscow
  volumes:
    - ./services/airflow/dags:/opt/airflow/dags
    - ./services/service_files:/opt/airflow/dags/service_files
    - ./services/airflow/airflow-data/logs:/opt/airflow/logs
    - ./services/airflow/airflow-data/plugins:/opt/airflow/plugins
    - ./services/airflow/airflow-data/airflow.cfg:/opt/airlfow/airflow.cfg
    - type: bind
        source: models
        target: /opt/airflow
  depends_on:
    - postgres

services:
  postgres:
    build:
      context: ./services/postgres
      dockerfile: ./Dockerfile
    container_name: postgres
    restart: always
    environment:
      - POSTGRES_MULTIPLE_DATABASES=investing_db,airflow,mlflow
      - POSTGRES_USER=investing_main_user
      - POSTGRES_PASSWORD=investing_main_user
      - PGDATA=/var/lib/postgresql/data/pgdata
    volumes:
      - postgres:/var/lib/postgresql/data
    ports:
      - 5432:5432
    networks:
      postgres:

  pgadmin:
    container_name: pgadmin
    image: dpage/pgadmin4
    environment:
      PGADMIN_DEFAULT_EMAIL: "investing_db@test.com"
      PGADMIN_DEFAULT_PASSWORD: "investing_db"
    volumes:
      - pgadmin:/var/lib/pgadmin
    expose:
      - 80
    restart: unless-stopped
    networks:
      postgres:
    depends_on:
      - postgres

  airflow-init:
    << : *airflow-common
    container_name: airflow_init
    command: >
      bash -c "airflow db init &&
                airflow users create --username admin --password admin --email admin@airflow.com --role Admin --firstname Admin --lastname Admin &&
                airflow connections add --conn-uri postgres://investing_main_user:investing_main_user@postgres:5432/investing_db postgres_conn &&
                airflow connections add --conn-uri mongo://operate_database:operate_database@192.168.1.13:27017 mongodb_conn &&
                airflow connections add --conn-uri http://export.finam.ru/ http_finam"
    depends_on:
      - postgres
    networks:
      postgres:

  airflow-webserver:
    << : *airflow-common
    container_name: airflow_webserver
    command: airflow webserver
    expose:
      - 8080
    restart: always
    depends_on:
      - airflow-init
    networks:
      postgres:

  airflow-scheduler:
    << : *airflow-common
    container_name: airflow_scheduler
    command: airflow scheduler
    restart: always
    depends_on:
      - airflow-init
    networks:
      postgres:

  mlflow:
    build:
      context: ./services/mlflow
      dockerfile: ./Dockerfile
    container_name: mlflow
    restart: on-failure
    command: mlflow server
      --backend-store-uri postgresql+psycopg2://investing_main_user:investing_main_user@postgres:5432/mlflow
      --default-artifact-root /mnt/mlruns
      --host 0.0.0.0
      --port 4040
    volumes:
      - ./services/mlflow/mnt/mlruns:/mnt/mlruns
      - mlflow:/backend
    expose:
      - 4040
    depends_on:
      - postgres
    networks:
      postgres:

  broker2:
    image: confluentinc/cp-server:latest
    container_name: broker2
    restart: always
    ports:
      - 39093:39093
      - 29093:29093
      - 9102:9102
    environment:
      KAFKA_BROKER_ID: 2
      ALLOW_PLAINTEXT_LISTENER: "yes"
      KAFKA_ZOOKEEPER_CONNECT: 192.168.1.13:22181
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://broker2:9093,EXTERNAL://localhost:29093,EXTERNAL_DIFFERENT://192.168.1.15:39093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,EXTERNAL_DIFFERENT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: EXTERNAL_DIFFERENT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_LOG_RETENTION_HOURS: 24
      KAFKA_LOG_RETENTION_BYTES: 1073741824
      KAFKA_LOG_SEGMENT_BUTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 20000
      KAFKA_LOG_SEGMENT_DELETE_DELAY_MS: 1000
      KAFKA_METADATA_MAX_RETENTION_MS: 86400000
      KAFKA_OFFSETS_RETENTION_MINUTES: 14400000
      KAFKA_LOG_CLEANER_DELETE_RETENTION_MS: 3600000
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_HEAP_OPTS: "-Xms512m -Xmx512m"
      CONFLUENT_METRICS_ENABLE: 'false'
    networks:
      postgres:

  broker3:
    image: confluentinc/cp-server:latest
    container_name: broker3
    restart: always
    ports:
      - 39094:39094
      - 29094:29094
      - 9103:9103
    environment:
      KAFKA_BROKER_ID: 3
      ALLOW_PLAINTEXT_LISTENER: "yes"
      KAFKA_ZOOKEEPER_CONNECT: 192.168.1.13:22181
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://broker3:9094,EXTERNAL://localhost:29094,EXTERNAL_DIFFERENT://192.168.1.15:39094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,EXTERNAL_DIFFERENT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: EXTERNAL_DIFFERENT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_LOG_RETENTION_HOURS: 24
      KAFKA_LOG_RETENTION_BYTES: 1073741824
      KAFKA_LOG_SEGMENT_BUTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 20000
      KAFKA_LOG_SEGMENT_DELETE_DELAY_MS: 1000
      KAFKA_METADATA_MAX_RETENTION_MS: 86400000
      KAFKA_OFFSETS_RETENTION_MINUTES: 14400000
      KAFKA_LOG_CLEANER_DELETE_RETENTION_MS: 3600000
      KAFKA_DELETE_TOPIC_ENABLE: "true"
#      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_HEAP_OPTS: "-Xms512m -Xmx512m"
#      KAFKA_JMX_PORT: 9103
#      KAFKA_JMX_HOSTNAME: localhost
#      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: 192.168.1.15:39094
      CONFLUENT_METRICS_ENABLE: 'false'
    networks:
      postgres:


  kafka_data_worker:
    build:
      context: ./services/kafka
      dockerfile: ./Dockerfile
    container_name: kafka_data_worker
    restart: always
    command: python data_worker.py -f data -t features  -bs 192.168.1.13:39092 -db1 investing_main_user:investing_main_user:investing_db:postgres:5432 -db2 operate_database:operate_database:192.168.1.13:27017:investing
    volumes:
      - ./services/service_files:/home/app
      - type: bind
          source: models
          target: /home/app
    depends_on:
      - kafka_feature_worker
    networks:
      postgres:

  kafka_feature_worker:
    build:
      context: ./services/kafka
      dockerfile: ./Dockerfile
    container_name: kafka_feature_worker
    restart: always
    command: python data_worker.py -f features -t predicts -bs 192.168.1.13:39092 -db1 investing_main_user:investing_main_user:investing_db:postgres:5432 -db2 operate_database:operate_database:192.168.1.13:27017:investing
    volumes:
      - ./services/service_files:/home/app
      - type: bind
          source: models
          target: /home/app
    depends_on:
      - kafka_predicts_worker
    networks:
      postgres:

  kafka_predicts_worker:
    build:
      context: ./services/kafka
      dockerfile: ./Dockerfile
    container_name: kafka_predicts_worker
    restart: always
    command: python data_worker.py -f predicts -t empty -bs 192.168.1.13:39092 -db1 investing_main_user:investing_main_user:investing_db:postgres:5432 -db2 operate_database:operate_database:192.168.1.13:27017:investing
    volumes:
      - ./services/service_files:/home/app
      - type: bind
          source: models
          target: /home/app
    depends_on:
      - broker2
    networks:
      postgres:


  nginx:
    build:
      context: ./services/nginx
      dockerfile: ./Dockerfile
      args:
        NGINX_CONFIG_PATH: db-nginx.conf
    container_name: db_nginx
    restart: always
    ports:
      - 5050:80
      - 8080:8080
      - 4040:4040
    networks:
      postgres:
    links:
      - postgres
    depends_on:
      - airflow-init

networks:
  postgres:

volumes:
  postgres:
  pgadmin:
  mlflow:

